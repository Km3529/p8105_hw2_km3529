---
title: "p8105_hw2_km3529"
author: Karina Myers
output: github_document
---

```{r setup}
library(tidyverse)
library(readxl)
```

## Problem 1

```{r Loading Mr. Trashwheel}
path_to_data = "./data/Trash-Wheel-Collection-Totals-8-6-19.xlsx"
```

Read the Mr. Trashwheel dataset

```{r}
trashwheel_df = 
	read_xlsx(
		path = path_to_data,
		sheet = "Mr. Trash Wheel",
		range = cell_cols("A:N")) %>% 
	janitor::clean_names() %>% 
	drop_na(dumpster) %>% 
	mutate(
		sports_balls = round(sports_balls),
		sports_balls = as.integer(sports_balls)
	)
```


Read precipitation data for 2017 and 2018

```{r 2018 and 2017}
#setting up 2018
precip_2018 = 
	read_excel(
		"./data/Trash-Wheel-Collection-Totals-8-6-19.xlsx",
		sheet = "2018 Precipitation",
		skip = 1
	) %>% 
	janitor::clean_names() %>% 
	drop_na(month) %>% 
	mutate(year = 2018) %>% 
	relocate(year)

#setting up 2017
precip_2017 = 
	read_excel(
		"./data/Trash-Wheel-Collection-Totals-8-6-19.xlsx",
		sheet = "2017 Precipitation",
		skip = 1
	) %>% 
	janitor::clean_names() %>% 
	drop_na(month) %>% 
	mutate(year = 2017) %>% 
	relocate(year)
```

Combine precipitation datasets 
```{r Combine}
month_df = 
	tibble(
		month = 1:12,
		month_name = month.name
	)
precip_df = 
	bind_rows(precip_2018, precip_2017)
precip_df =
	left_join(precip_df, month_df, by = "month") %>% 
  select(-month) %>% 
  rename(month = month_name) %>%
  relocate(year,month)
```

This dataset contains information from the Mr. Trashwheel trash collector in Baltimore, Maryland. As trash enters the inner harbor, the trashwheel collects that trash, and stores it in a dumpster. The dataset contains information on year, month, and trash collected, include some specific kinds of trash. There are `r nrow(trashwheel_df)` rows and `r ncol(trashwheel_df)` columns. In this dataset: The median number of sports balls found in a dumpster in 2017 was `r trashwheel_df %>% filter(year == 2017) %>% pull(sports_balls) %>% median()`
Additional data sheets include month and precipitation data. When looking at precipatation in 2018 and 2017, there are a total of `r nrow(precip_df)` rows and `r ncol(precip_df)` in our final dataset. The total precipitation in 2018 was `r precip_df %>% filter(year == 2018) %>% pull(total) %>% sum()` inches. The total preciptation in 2018 was `r precip_df %>%  filter(year == 2017) %>% pull(total) %>% sum()` inches. 

## Problem 2
Load NYC Transit Data 
```{r NYC Transit}
transit_df = 
  read_csv("./data/NYC_Transit_Subway_Entrance_And_Exit_Data.csv") %>% 
  janitor::clean_names() %>% 
  select(line:entry, vending, ada) %>% 
  mutate(
      entry = as.character(entry), 
      entry = replace(entry, entry == "YES", "TRUE"), 
        entry = replace(entry, entry == "NO", "FALSE"), 
      entry = as.logical(entry))
```

This dataset contains information on the New York City subway system. It includes data on station lines, station coordinates, entrance types, and ADA accessibility. It also provides route name information, as many stops have many lines.  After importing the data, the names of variables were converted to snake case. Certain variables such as ADA notes were dropped and only the variables of interest were included. Entry was then converted from a character variable to a logical variable. While the latitude the NYC subway system range from `r range(transit_df$station_latitude)`, the longtidue covers `r range(transit_df$station_longitude)`. There are a total of `r nrow(transit_df)` rows and `r ncol(transit_df)`. The data are not tidy because there are multiple columns describing route names. A tidyier way to present this would be to have a different row for each route number. 

Find the number of distinct stations 
```{r Distinct Stations}
distinct(transit_df, line, station_name) %>% 
  count()
```

ADA compliant stations
```{r ADA compliant}
filter(transit_df, ada == TRUE) %>% 
distinct(line, station_name) %>% 
count()
```

Proportion of entrances/exists without vending that allow entrance
```{r Proportion}

a = filter(transit_df, vending != "YES" 
      & entry == TRUE) %>% 
  count()

b = filter(transit_df, vending != "YES") %>% 
  count()

a/b

```
The proportion of station entrances and exists without vending that allow entrance is `r a/b`. 

Reformat so route number and route name are distinct variables
```{r Reformat}
transit_tidy =
  read_csv("./data/NYC_Transit_Subway_Entrance_And_Exit_Data.csv",
    col_types = "cccnnccccccccccccccccclclcccnncc") %>% 
  janitor::clean_names() %>% 
  select(line:entry, vending, ada) %>% 
  mutate(
      entry = as.character(entry), 
      entry = replace(entry, entry == "YES", "TRUE"), 
        entry = replace(entry, entry == "NO", "FALSE"), 
      entry = as.logical(entry)) %>% 
  pivot_longer(
    route1:route11, 
    names_to = "route_name", 
    values_to = "route_number") %>% 
  drop_na(route_number)
```


Serve the A Train
```{r A train}
#A Train
filter(transit_tidy, route_number == "A") %>% 
  distinct(line, station_name) %>% 
  count()

# ADA accessible A Train Stations
filter(transit_tidy, 
      route_number == "A" &
        ada == TRUE) %>% 
  distinct(line, station_name) %>% 
  count()
```

## Problem 3

Clean the pols-month data
```{r Pols-month}
month_df = 
  tibble(
      month = 1:12, 
      month_name = month.abb)

pols_df = 
  read_csv("./data/fivethirtyeight_datasets/pols-month.csv") %>% 
  janitor::clean_names() %>% 
  separate(mon, into = c("year", "month", "day")) %>% 
  mutate(month = as.integer(month)) %>% 
  mutate(day = as.integer(day)) %>% 
  mutate(year = as.integer(year))

pols_df =
  left_join(pols_df, month_df, by = "month")  %>% 
  select(-month, -day) %>% 
  rename(month = month_name) %>% 
  mutate(
      president = case_when(
        prez_dem == 0 ~ "gop", 
        prez_dem == 1 ~ "dem")) %>% 
  relocate(year, month) 

```


Clean the snp data 
```{r Snp}
 month_df = 
  tibble(
      month = 1:12, 
      month_name = month.abb)

snp_df = 
  read_csv("./data/fivethirtyeight_datasets/snp.csv") %>% 
  janitor::clean_names() %>% 
  separate(date, into = c("month", "day", "year")) %>% 
  mutate(month = as.numeric(month)) %>% 
  mutate(year = as.numeric(year)) %>% 
  mutate(day = as.numeric(day))

snp_df = 
 left_join(snp_df, month_df, by = "month")  %>% 
  select(-month, -day) %>% 
  rename(month = month_name) %>% 
  relocate(year, month)

```


unemployment data 
```{r}
 month_df = 
  tibble(
      month = 1:12, 
      month_name = month.abb)

unemployment_df = 
  read_csv("./data/fivethirtyeight_datasets/unemployment.csv") %>% 
  janitor::clean_names()

unemployment_tidy =
  unemployment_df %>% 
  pivot_longer(
    jan:dec,
    names_to = "month", 
    values_to = "unemp") %>% 
  mutate(month = str_to_title(month))

```

```{r merge}
merge_df = 
  left_join(pols_df, snp_df, by = c("year", "month"))
  
final_df = 
  left_join(merge_df, unemployment_tidy, by = c("year", "month"))
```

The pols-month dataset contains political party composition per month between the years of  `r range(pols_df$)`. It contains political party information on senators, governors, representatives, and the president. The snp dataset contains information about the Standard & Poor's stock market index (S&P). This index is used as a measure of the stock market as a whole. S&P values were collected every month between `r range(snp_df$year)`. The recorded scores range between `r range(snp_df$close)` and the average closing score was `r mean(snp_df$close)`. The unemployment dataset contains the percent of people unemployed in the United States between the years of `r range(unemployment_tidy$year). During this time, the median unemployment rate was `r median(unemployment_tidy$unemp)`. 

After merging the three dataset, there are `r nrows(final_df)` rows and `r ncol(final_df)`. It contains information on political partly affiliations of presidents, senators, representatives and governors, the unemployment rate, and the S&P closing index between the years of `r range(final_df$year)`. During the time, average unemployment rate was `r mean(final_df$unemp)` and it ranged between `r range(final_df$unemp). 
